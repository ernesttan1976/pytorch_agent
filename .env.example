# Hugging Face Token (required for gated models like Llama)
HF_TOKEN=your_huggingface_token_here

# CUDA Device Selection (optional, defaults to all available)
# CUDA_VISIBLE_DEVICES=0

# Weights & Biases (optional, for experiment tracking)
# WANDB_API_KEY=your_wandb_key_here
# WANDB_PROJECT=llm-finetuning
# WANDB_RUN_NAME=qlora_sft

# Training Output Directory (optional, defaults to runs/)
# OUTPUT_DIR=runs

# Model Cache Directory (optional, defaults to ~/.cache/huggingface/)
# HF_HOME=/path/to/model/cache

# WSL2 CUDA Settings (may be needed for WSL2)
# CUDA_HOME=/usr/local/cuda
# LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH
